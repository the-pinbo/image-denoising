{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-10 17:27:35.116968: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-10 17:27:35.833231: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-10 17:27:35.833295: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-10 17:27:35.833301: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# @title Importing modules\n",
    "from CustomDataGen import CustomDataGen\n",
    "import Constants\n",
    "import Util\n",
    "import Plot\n",
    "import Preprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "import Model\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-10 17:27:47.909969: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-10 17:27:47.925513: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-10 17:27:47.944231: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-10 17:27:47.944555: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-10 17:27:48.469496: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-10 17:27:48.469699: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-10 17:27:48.469835: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-10 17:27:48.469965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /device:GPU:0 with 2574 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title Tensor flow gpu check\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Setting up download path\n",
    "DATA_ROOT = \"./\"\n",
    "DATASET_NAME = \"bsd\"\n",
    "ORIGIN_URL = \"http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/BSR/BSR_bsds500.tgz\"\n",
    "DOWNLOAD_DIR = DATA_ROOT + \"dataset\" + \"/\" + DATASET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./dataset/bsd'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DOWNLOAD_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded successfully in /tmp/.keras/./dataset/flickr8k/Flickr8k_Dataset.zip\n"
     ]
    }
   ],
   "source": [
    "# @title Downloading flickr8k dataset\n",
    "Util.download_dataset(ORIGIN_URL, DOWNLOAD_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Creating directories for pre-processing images \n",
    "CLEAN_IMG_SUB_DIR = \"/Flicker8k_Dataset\"\n",
    "CLEAN_IMG_DIR = DOWNLOAD_DIR + CLEAN_IMG_SUB_DIR\n",
    "NOISE_DIR = DOWNLOAD_DIR + \"/noise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ./dataset/flickr8k/noise already exists\n",
      " ./dataset/flickr8k/noise/m_0__v_0 already exists\n",
      " ./dataset/flickr8k/noise/m_0__v_0/noise_1 already exists\n",
      " ./dataset/flickr8k/noise/m_0__v_0/noise_2 already exists\n"
     ]
    }
   ],
   "source": [
    "Util.make_dir(NOISE_DIR)\n",
    "NOISE_DIR = NOISE_DIR + \\\n",
    "    f\"/m_{Constants.MEAN}__v_{Constants.MEAN}\".replace(\".\", \"d\")\n",
    "Util.make_dir(NOISE_DIR)\n",
    "NOISE_1_DIR = NOISE_DIR + \"/noise_1\"\n",
    "Util.make_dir(NOISE_1_DIR)\n",
    "NOISE_2_DIR = NOISE_DIR + \"/noise_2\"\n",
    "Util.make_dir(NOISE_2_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Pre-processing images \n",
    "Preprocess.preprocess_images(CLEAN_IMG_DIR, NOISE_1_DIR, NOISE_2_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Plot first n images from clean and noise dirs \n",
    "n = 4  # @param {type:\"slider\", min:1, max:15, step:1}\n",
    "Plot.plot_first_n(n, CLEAN_IMG_DIR, NOISE_1_DIR, NOISE_2_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_1_paths = pd.Series(Util.get_noise_img_path(\n",
    "    CLEAN_IMG_DIR, NOISE_1_DIR), name='noise_1').astype(str)\n",
    "\n",
    "noise_1_paths.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_2_paths = pd.Series(Util.get_noise_img_path(\n",
    "    CLEAN_IMG_DIR, NOISE_2_DIR), name='noise_2').astype(str)\n",
    "\n",
    "noise_2_paths.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_df = pd.concat([noise_1_paths, noise_2_paths], axis=1).sample(\n",
    "    frac=1.0, random_state=1).reset_index(drop=True)\n",
    "images_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.70  # @param {type:\"slider\", min:0, max:1, step:0.01}\n",
    "train_df, test_df = train_test_split(\n",
    "    images_df, train_size=train_size, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traingen = CustomDataGen(train_df)\n",
    "print(f\"Number of train batches {len(traingen)}\")\n",
    "\n",
    "valgen = CustomDataGen(test_df)\n",
    "print(f\"Number of validation batches {len(valgen)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model.UNet()\n",
    "autoencoder_optimizer = tf.keras.optimizers.Adam(Constants.LEARNING_RATE, beta_1=Constants.BETA_1)\n",
    "autoencoder.compile(\n",
    "    optimizer=\"adam\", loss=tf.keras.losses.MeanSquaredError(), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = \"unet_1\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"my_model/gauss\" + \\\n",
    "    f\"/m_{Constants.MEAN}__v_{Constants.VAR}\".replace(\n",
    "        \".\", \"d\") + f\"_version_{VERSION}\"\n",
    "monitor = \"val_accuracy\"\n",
    "mode = \"max\"\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_path,\n",
    "    monitor=monitor,\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode=mode,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Train the model\n",
    "EPOCHS = 15\n",
    "history = autoencoder.fit(traingen,\n",
    "                          validation_data=valgen,\n",
    "                          epochs=EPOCHS,\n",
    "                          shuffle=True,\n",
    "                          callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot.plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME = \"./models/\" + f\"/m_{Constants.MEAN}__v_{Constants.VAR}\".replace(\n",
    "    \".\", \"d\") + f\"_version_{VERSION}\" + DATASET_NAME + \".h\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_LITE_NAME = \"models_tf_lite/\" + \\\n",
    "    f\"/m_{Constants.MEAN}__v_{Constants.VAR}\".replace(\".\", \"d\") + \\\n",
    "    f\"_version_{VERSION}\" + DATASET_NAME + \".h\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Util.save_model(FILE_NAME, autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Util.save_tf_lite(FILE_NAME, autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for noise_img_path in test_df[\"noise_1\"][:5]:\n",
    "    Plot.vsualize_predictions(autoencoder,noise_img_path,CLEAN_IMG_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
